{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "BENCHMARKS = ['hh_bench', 'ihap_bench', 'mt_bench', 'vicuna_bench']\n",
    "MODEL_PARALLEL = {\n",
    "    # 'Locutusque/TinyMistral-248M-v2.5': 12, #done\n",
    "    # 'TinyLlama/TinyLlama-1.1B-Chat-v1.0': 10, #done\n",
    "    # 'Writer/palmyra-small': 10, #done\n",
    "    # 'Writer/palmyra-3B': 4, #done\n",
    "    # 'lmsys/vicuna-7b-v1.5': 2, #done\n",
    "    # 'lmsys/vicuna-13b-v1.5': 1, #done\n",
    "    # 'mistralai/Mistral-7B-Instruct-v0.2': 2, #done\n",
    "    # 'microsoft/phi-2': 8, #done\n",
    "    # 'microsoft/phi-1_5': 10, #done\n",
    "    # 'abacaj/phi-2-super': 6, #done\n",
    "    # 'AbacusResearch/RasGulla1-7b': 2 #done\n",
    "    # 'Jiayi-Pan/Tiny-Vicuna-1B': 10,\n",
    "    # 'pansophic/rocket-3B': 4,\n",
    "}\n",
    "\n",
    "for model in MODEL_PARALLEL:\n",
    "    name = model.split('/')[1]\n",
    "    gpus = MODEL_PARALLEL[model]\n",
    "    for bench in BENCHMARKS:\n",
    "        subprocess.run(f\"python3 scripts/gen_model_answer.py --model-path {model} --model-id {name} --num-gpus-total {gpus} --bench-name {bench}\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os \n",
    "\n",
    "BENCHMARKS = ['hh_bench', 'ihap_bench', 'mt_bench', 'vicuna_bench']\n",
    "\n",
    "for bench in BENCHMARKS:\n",
    "    names = os.listdir(f'data/{bench}/model_answer/')\n",
    "    names = [name.split('.jsonl')[0] for name in names]\n",
    "    names = ' '.join(names)\n",
    "    subprocess.run(f\"python3.11 scripts/gen_judgement.py --model-list {names} --parallel 30 --bench-name {bench} --judge-model gpt-4-0125-preview\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: single\n",
      "Input file: data/hh_bench/model_judgment/gpt-4-0125-preview_single.jsonl\n",
      "                          score  (timing, mean)  (timing, percentile_10)  (timing, percentile_90)\n",
      "model                                                                                            \n",
      "RasGulla1-7b               8.27      659.715738               289.993370               994.407894\n",
      "Mistral-7B-Instruct-v0.2   8.04      497.928455               301.869942               706.817139\n",
      "vicuna-13b-v1.5            7.51      471.189719               132.276882               885.147056\n",
      "vicuna-7b-v1.5             7.18      444.754299               183.131315               677.706057\n",
      "phi-2                      6.32      433.785022               109.063317               953.750931\n",
      "phi-2-super                5.89      369.120306               345.957803               415.019126\n",
      "TinyLlama-1.1B-Chat-v1.0   5.23      200.735050                83.657845               297.832495\n",
      "phi-1_5                    4.58      147.442111               142.646331               151.824654\n",
      "palmyra-3B                 2.86      103.561350               102.552085               106.862860\n",
      "palmyra-small              1.18       62.461301                24.913231                76.375889\n",
      "TinyMistral-248M-v2.5      1.00       53.647013                50.799961                56.315217\n",
      "Mode: single\n",
      "Input file: data/ihap_bench/model_judgment/gpt-4-0125-preview_single.jsonl\n",
      "                          score  (timing, mean)  (timing, percentile_10)  (timing, percentile_90)\n",
      "model                                                                                            \n",
      "RasGulla1-7b               8.35      407.738971               199.082198               664.350423\n",
      "Mistral-7B-Instruct-v0.2   8.31      331.010019               189.880810               467.413416\n",
      "vicuna-13b-v1.5            7.46      337.683239               148.802794               468.080559\n",
      "phi-2                      7.45      255.772412                77.355375               508.944478\n",
      "vicuna-7b-v1.5             7.41      238.207103               141.107203               338.467864\n",
      "phi-2-super                7.26      184.597330               174.098466               205.371425\n",
      "TinyLlama-1.1B-Chat-v1.0   6.21      169.468690                96.897633               252.747914\n",
      "phi-1_5                    5.89      148.593672               141.099598               153.299287\n",
      "palmyra-3B                 3.47      135.936078               134.538741               142.114535\n",
      "palmyra-small              1.23      139.027868               133.349921               150.241893\n",
      "TinyMistral-248M-v2.5      1.00      107.548492               100.878076               113.297252\n",
      "Mode: single\n",
      "Input file: data/mt_bench/model_judgment/gpt-4-0125-preview_single.jsonl\n",
      "                             score  (timing, mean)  (timing, percentile_10)  (timing, percentile_90)\n",
      "model                                                                                               \n",
      "RasGulla1-7b              6.875000      601.621107               126.153707              1393.086918\n",
      "Mistral-7B-Instruct-v0.2  6.787500      457.993585                97.138065               857.325430\n",
      "vicuna-13b-v1.5           5.829268      409.044941                41.704788               857.824201\n",
      "phi-2                     5.812500      447.601052                83.167822              1204.654238\n",
      "vicuna-7b-v1.5            5.812500      408.683590                85.454056               829.449132\n",
      "palmyra-3B                5.654321      275.796266                85.122120               619.566635\n",
      "phi-2-super               5.426829      231.799454               195.890469               278.201503\n",
      "phi-1_5                   3.904762      216.308649               182.191603               284.662934\n",
      "TinyLlama-1.1B-Chat-v1.0  3.506173      155.264986                26.364214               299.127541\n",
      "palmyra-small             3.246914       94.202908                 9.701539               227.237282\n",
      "TinyMistral-248M-v2.5     1.000000       65.906637                50.749039                94.732200\n",
      "Mode: single\n",
      "Input file: data/vicuna_bench/model_judgment/gpt-4-0125-preview_single.jsonl\n",
      "                           score  (timing, mean)  (timing, percentile_10)  (timing, percentile_90)\n",
      "model                                                                                             \n",
      "Mistral-7B-Instruct-v0.2  8.1000      364.967484               233.406853               538.496376\n",
      "RasGulla1-7b              7.8750      307.601593               149.561674               648.443349\n",
      "phi-2                     7.0375      288.253770               112.334852               546.380072\n",
      "vicuna-13b-v1.5           6.9125      271.979689               118.961712               439.354835\n",
      "phi-2-super               6.6625      181.955343               173.682975               205.621541\n",
      "vicuna-7b-v1.5            6.3625      169.982997                79.802274               271.854781\n",
      "TinyLlama-1.1B-Chat-v1.0  5.4875      145.940792                54.074841               239.125828\n",
      "phi-1_5                   5.4250      104.574691               102.900223               106.526821\n",
      "palmyra-3B                2.6250      103.240133                83.498762               113.404877\n",
      "palmyra-small             1.1000       64.955747                40.152384                75.145442\n",
      "TinyMistral-248M-v2.5     1.0000       57.307703                53.600314                60.790598\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os \n",
    "\n",
    "BENCHMARKS = ['hh_bench', 'ihap_bench', 'mt_bench', 'vicuna_bench']\n",
    "\n",
    "for bench in BENCHMARKS:\n",
    "    names = os.listdir(f'data/{bench}/model_answer/')\n",
    "    names = [name.split('.jsonl')[0] for name in names]\n",
    "    names = ' '.join(names)\n",
    "    subprocess.run(f\"python3.11 -W ignore scripts/show_result.py --model-list {names} --bench-name {bench}\".split(\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
